{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b86e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2+cu121\n",
      "Menggunakan device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Cek ketersediaan GPU dan atur device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Menggunakan device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826bd4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "      <th>rating</th>\n",
       "      <th>Usia</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Lokasi Tinggal</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433221332117</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Tidak Ingin Menjawab</td>\n",
       "      <td>Bali</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433224214164</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Tidak Ingin Menjawab</td>\n",
       "      <td>Papua Barat</td>\n",
       "      <td>Otomotif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433221999827</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;18</td>\n",
       "      <td>Laki - laki</td>\n",
       "      <td>Sulawesi Tengah</td>\n",
       "      <td>Kesehatan &amp; Kecantikan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433221955914</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>Kalimantan Tengah</td>\n",
       "      <td>Fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433221337106</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;18</td>\n",
       "      <td>Perempuan</td>\n",
       "      <td>Nusa Tenggara Timur</td>\n",
       "      <td>Kesehatan &amp; Kecantikan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp  visitorid event  itemid  transactionid  rating   Usia  \\\n",
       "0  1433221332117     257597  view  355908            NaN       1  25-34   \n",
       "1  1433224214164     992329  view  248676            NaN       1  35-44   \n",
       "2  1433221999827     111016  view  318965            NaN       1    <18   \n",
       "3  1433221955914     483717  view  253185            NaN       1  25-34   \n",
       "4  1433221337106     951259  view  367447            NaN       1    <18   \n",
       "\n",
       "                 Gender       Lokasi Tinggal                category  \n",
       "0  Tidak Ingin Menjawab                 Bali                 Fashion  \n",
       "1  Tidak Ingin Menjawab          Papua Barat                Otomotif  \n",
       "2           Laki - laki      Sulawesi Tengah  Kesehatan & Kecantikan  \n",
       "3             Perempuan    Kalimantan Tengah                 Fashion  \n",
       "4             Perempuan  Nusa Tenggara Timur  Kesehatan & Kecantikan  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(\"Final_Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "900e770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data siap: 2755641 interaksi, 1407580 user, 235061 item, 8 kategori.\n",
      "Fitur demografis: 5 rentang usia, 3 gender, 34 lokasi.\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding untuk user, item, dan fitur demografis\n",
    "encoders = {\n",
    "    'user': LabelEncoder(),\n",
    "    'item': LabelEncoder(),\n",
    "    'age': LabelEncoder(),\n",
    "    'gender': LabelEncoder(),\n",
    "    'location': LabelEncoder(),\n",
    "    'category': LabelEncoder()\n",
    "}\n",
    "\n",
    "df['user_idx'] = encoders['user'].fit_transform(df['visitorid'])\n",
    "df['item_idx'] = encoders['item'].fit_transform(df['itemid'])\n",
    "df['age_idx'] = encoders['age'].fit_transform(df['Usia'])\n",
    "df['gender_idx'] = encoders['gender'].fit_transform(df['Gender'])\n",
    "df['location_idx'] = encoders['location'].fit_transform(df['Lokasi Tinggal'])\n",
    "df['category_idx'] = encoders['category'].fit_transform(df['category'])\n",
    "\n",
    "# Simpan jumlah kategori unik untuk setiap fitur\n",
    "n_users = df['user_idx'].nunique()\n",
    "n_items = df['item_idx'].nunique()\n",
    "n_ages = df['age_idx'].nunique()\n",
    "n_genders = df['gender_idx'].nunique()\n",
    "n_locations = df['location_idx'].nunique()\n",
    "n_categories = df['category_idx'].nunique()\n",
    "\n",
    "print(f\"Data siap: {len(df)} interaksi, {n_users} user, {n_items} item, {n_categories} kategori.\")\n",
    "print(f\"Fitur demografis: {n_ages} rentang usia, {n_genders} gender, {n_locations} lokasi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6d1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Encoding\n",
    "df.to_csv('encoded_data_2tower.csv', index=False)\n",
    "\n",
    "for name, encoder in encoders.items():\n",
    "    joblib.dump(encoder, f\"{name}_encoder_2tower.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Encoding\n",
    "df = pd.read_csv('encoded_data_2tower.csv')\n",
    "\n",
    "encoders = {name: joblib.load(f\"{name}_encoder_2tower.pkl\") for name in ['user','item','age','gender','location','category']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc69fbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Training (Warm): 1073630\n",
      "Data Test (Warm): 268408\n",
      "Data Test (User Cold): 200000\n",
      "Data Test (Item Cold): 9962\n"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "MIN_INTERACTIONS = 3\n",
    "SAMPLE_SIZE = 200000\n",
    "NUM_NEGATIVES = 4\n",
    "\n",
    "user_counts = df['user_idx'].value_counts()\n",
    "inactive_users = user_counts[user_counts < MIN_INTERACTIONS].index\n",
    "active_users = user_counts[user_counts >= MIN_INTERACTIONS].index\n",
    "\n",
    "user_cold_start_raw = df[df['user_idx'].isin(inactive_users)]\n",
    "user_cold_start_test_df = user_cold_start_raw.sample(n=min(len(user_cold_start_raw), SAMPLE_SIZE), random_state=42)\n",
    "\n",
    "warm_df = df[df['user_idx'].isin(active_users)]\n",
    "train_df, test_warm_df = train_test_split(warm_df, test_size=0.2, random_state=42, stratify=warm_df['user_idx'])\n",
    "\n",
    "train_items_set = set(train_df['item_idx'])\n",
    "item_cold_start_test_df = test_warm_df[~test_warm_df['item_idx'].isin(train_items_set)]\n",
    "\n",
    "print(f\"Data Training (Warm): {len(train_df)}\")\n",
    "print(f\"Data Test (Warm): {len(test_warm_df)}\")\n",
    "print(f\"Data Test (User Cold): {len(user_cold_start_test_df)}\")\n",
    "print(f\"Data Test (Item Cold): {len(item_cold_start_test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b084e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d74f4c31a844948a31c7da5ec546df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Negative Samples:   0%|          | 0/1073630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran data training diperluas: 5368150 sampel.\n"
     ]
    }
   ],
   "source": [
    "# Buat set semua interaksi untuk pengecekan cepat\n",
    "user_item_set = set(zip(df['user_idx'], df['item_idx']))\n",
    "\n",
    "# Buat mapping item_idx ke category_idx untuk lookup cepat\n",
    "item_to_category = df.drop_duplicates('item_idx').set_index('item_idx')['category_idx'].to_dict()\n",
    "\n",
    "# Ambil data positif\n",
    "pos_users = train_df['user_idx'].values\n",
    "pos_items = train_df['item_idx'].values\n",
    "pos_ages = train_df['age_idx'].values\n",
    "pos_genders = train_df['gender_idx'].values\n",
    "pos_locations = train_df['location_idx'].values\n",
    "pos_categories = train_df['category_idx'].values\n",
    "pos_ratings = train_df['rating'].values\n",
    "\n",
    "# Siapkan list final\n",
    "train_data = {k: [] for k in ['users', 'items', 'ages', 'genders', 'locations', 'categories', 'labels']}\n",
    "\n",
    "# Tambahkan data positif\n",
    "for i in range(len(train_df)):\n",
    "    for key, L in [('users',pos_users), ('items',pos_items), ('ages',pos_ages), ('genders',pos_genders), \n",
    "                   ('locations',pos_locations), ('categories', pos_categories), ('labels', pos_ratings)]:\n",
    "        train_data[key].append(L[i])\n",
    "\n",
    "# Generate data negatif\n",
    "neg_items_array = np.random.randint(0, n_items, size=(len(train_df), NUM_NEGATIVES))\n",
    "for i in tqdm(range(len(train_df)), desc=\"Generating Negative Samples\"):\n",
    "    user = pos_users[i]\n",
    "    for j in range(NUM_NEGATIVES):\n",
    "        neg_item = neg_items_array[i, j]\n",
    "        while (user, neg_item) in user_item_set:\n",
    "            neg_item = np.random.randint(0, n_items)\n",
    "        neg_items_array[i, j] = neg_item\n",
    "        \n",
    "        # Tambahkan data negatif\n",
    "        train_data['users'].append(user)\n",
    "        train_data['items'].append(neg_item)\n",
    "        train_data['labels'].append(0)\n",
    "        # Salin fitur demografi user & kategori item\n",
    "        train_data['ages'].append(pos_ages[i])\n",
    "        train_data['genders'].append(pos_genders[i])\n",
    "        train_data['locations'].append(pos_locations[i])\n",
    "        train_data['categories'].append(item_to_category.get(neg_item, 0))\n",
    "\n",
    "training_df_final = pd.DataFrame(train_data)\n",
    "print(f\"Ukuran data training diperluas: {len(training_df_final['labels'])} sampel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bde7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save negatif train\n",
    "training_df_final.to_csv(\"train_negsamp_2tower.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load negatif train\n",
    "training_df_final = pd.read_csv(\"train_negsamp_2tower.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e14396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_samples(test_df, all_items, user_item_dict, item_to_category, num_negatives=99, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    all_items = np.array(all_items)\n",
    "    test_with_neg = []\n",
    "\n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Generating Negatives\", mininterval=1.0):\n",
    "        user = int(row['user_idx'])\n",
    "        pos_item = int(row['item_idx'])\n",
    "        seen_items = user_item_dict.get(user, set())\n",
    "        \n",
    "        # ambil calon item negatif acak\n",
    "        neg_items = []\n",
    "        while len(neg_items) < num_negatives:\n",
    "            candidates = np.random.choice(all_items, size=num_negatives*2, replace=False)\n",
    "            valid = [i for i in candidates if i not in seen_items and i != pos_item]\n",
    "            neg_items.extend(valid)\n",
    "        neg_items = neg_items[:num_negatives]\n",
    "        \n",
    "        test_with_neg.append({\n",
    "            'user_idx': user,\n",
    "            'item_idx': pos_item,\n",
    "            'age_idx': int(row['age_idx']),\n",
    "            'gender_idx': int(row['gender_idx']),\n",
    "            'location_idx': int(row['location_idx']),\n",
    "            'category_idx': int(row['category_idx']),\n",
    "            'rating': row['rating'],\n",
    "            'neg_items': neg_items\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(test_with_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb369ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3109130982e64106af561f0a2753bba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Negatives:   0%|          | 0/268408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c53504348d14935a531d8eba5b95db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Negatives:   0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3889c7c339794bbfae74d4ebb300793f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Negatives:   0%|          | 0/9962 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate negatif test\n",
    "all_items = df['item_idx'].unique().tolist()\n",
    "user_item_dict = train_df.groupby('user_idx')['item_idx'].apply(set).to_dict()\n",
    "\n",
    "test_warm_with_neg = generate_negative_samples(test_warm_df, all_items, user_item_dict, item_to_category)\n",
    "user_cold_start_test_with_neg = generate_negative_samples(user_cold_start_test_df, all_items, user_item_dict, item_to_category)\n",
    "item_cold_start_test_with_neg = generate_negative_samples(item_cold_start_test_df, all_items, user_item_dict, item_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33cf87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save negatif test\n",
    "with open(\"test_warm_neg_2tower.pkl\", \"wb\") as f:\n",
    "    pickle.dump(test_warm_with_neg, f)\n",
    "\n",
    "with open(\"user_cold_start_test_neg_2tower.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_cold_start_test_with_neg, f)\n",
    "\n",
    "with open(\"item_cold_start_test_neg_2tower.pkl\", \"wb\") as f:\n",
    "    pickle.dump(item_cold_start_test_with_neg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff83d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load negatif test\n",
    "with open(\"test_warm_neg_2tower.pkl\", \"rb\") as f:\n",
    "    test_warm_with_neg = pickle.load(f)\n",
    "\n",
    "with open(\"user_cold_start_test_neg_2tower.pkl\", \"rb\") as f:\n",
    "    user_cold_start_test_with_neg = pickle.load(f)\n",
    "\n",
    "with open(\"item_cold_start_test_neg_2tower.pkl\", \"rb\") as f:\n",
    "    item_cold_start_test_with_neg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "774aa9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class FinalHybridDataset(Dataset):\n",
    "    def __init__(self, data_dict):\n",
    "        self.users = torch.tensor(data_dict['users'], dtype=torch.long)\n",
    "        self.items = torch.tensor(data_dict['items'], dtype=torch.long)\n",
    "        self.ages = torch.tensor(data_dict['ages'], dtype=torch.long)\n",
    "        self.genders = torch.tensor(data_dict['genders'], dtype=torch.long)\n",
    "        self.locations = torch.tensor(data_dict['locations'], dtype=torch.long)\n",
    "        self.categories = torch.tensor(data_dict['categories'], dtype=torch.long)\n",
    "        \n",
    "        self.labels = torch.tensor(data_dict['labels'], dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Kembalikan tensor dari atribut class\n",
    "        return (self.users[idx], self.items[idx], self.ages[idx], \n",
    "                self.genders[idx], self.locations[idx], \n",
    "                self.categories[idx], self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90509436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model NCF Final Two-Tower\n",
    "class FinalTwoTowerModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_ages, num_genders, num_locations, num_categories, embedding_dim=32):\n",
    "        super(FinalTwoTowerModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # --- User Tower ---\n",
    "        self.user_embed = nn.Embedding(num_users, embedding_dim)\n",
    "        self.age_embed = nn.Embedding(num_ages, 8)\n",
    "        self.gender_embed = nn.Embedding(num_genders, 4)\n",
    "        self.location_embed = nn.Embedding(num_locations, 8)\n",
    "        user_mlp_input_dim = embedding_dim + 8 + 4 + 8\n",
    "        self.user_tower = nn.Sequential(nn.Linear(user_mlp_input_dim, 64), nn.ReLU(), nn.Linear(64, embedding_dim))\n",
    "        \n",
    "        # --- Item Tower ---\n",
    "        self.item_embed = nn.Embedding(num_items, embedding_dim)\n",
    "        self.category_embed = nn.Embedding(num_categories, 16)\n",
    "        item_mlp_input_dim = embedding_dim + 16\n",
    "        self.item_tower = nn.Sequential(nn.Linear(item_mlp_input_dim, 64), nn.ReLU(), nn.Linear(64, embedding_dim))\n",
    "\n",
    "    def forward(self, user, item, age, gender, location, category):\n",
    "        # Proses User Tower\n",
    "        user_features = torch.cat([self.user_embed(user), self.age_embed(age), \n",
    "                                   self.gender_embed(gender), self.location_embed(location)], dim=-1)\n",
    "        user_vector = self.user_tower(user_features)\n",
    "        \n",
    "        # Proses Item Tower\n",
    "        item_features = torch.cat([self.item_embed(item), self.category_embed(category)], dim=-1)\n",
    "        item_vector = self.item_tower(item_features)\n",
    "        \n",
    "        # Prediksi dengan dot product\n",
    "        prediction = torch.sum(user_vector * item_vector, dim=1)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd1427f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi helper\n",
    "def hit_ratio_at_k(predictions, true_item_idx, k):\n",
    "    _, top_k_indices = torch.topk(predictions, k)\n",
    "    return 1 if true_item_idx in top_k_indices else 0\n",
    "\n",
    "def ndcg_at_k(predictions, true_item_idx, k):\n",
    "    _, top_k_indices = torch.topk(predictions, k)\n",
    "    indices = (top_k_indices == true_item_idx).nonzero(as_tuple=True)[0]\n",
    "    return 0.0 if indices.numel() == 0 else (1.0 / np.log2(indices.item() + 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb0a6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi evaluasi\n",
    "def evaluate_model(model, test_data, description):\n",
    "    if test_data.empty:\n",
    "        print(f\"\\n--- {description} ---\\nTidak ada data untuk dievaluasi.\")\n",
    "        return\n",
    "    \n",
    "    model.eval()\n",
    "    all_rmse, all_hr_at_10, all_ndcg_at_10 = [], [], []\n",
    "    print(f\"\\n--- {description} ---\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # === RMSE (hanya data positif) ===\n",
    "        test_loader = DataLoader(\n",
    "            TensorDataset(\n",
    "                torch.tensor(test_data['user_idx'].values),\n",
    "                torch.tensor(test_data['item_idx'].values),\n",
    "                torch.tensor(test_data['age_idx'].values),\n",
    "                torch.tensor(test_data['gender_idx'].values),\n",
    "                torch.tensor(test_data['location_idx'].values),\n",
    "                torch.tensor(test_data['category_idx'].values),\n",
    "                torch.tensor(test_data['rating'].values)\n",
    "            ), batch_size=2048, shuffle=False\n",
    "        )\n",
    "\n",
    "        for users, items, ages, genders, locs, cats, ratings in test_loader:\n",
    "            users, items, ages, genders, locs, cats, ratings = [\n",
    "                t.to(device) for t in [users, items, ages, genders, locs, cats, ratings]\n",
    "            ]\n",
    "            predictions = model(users, items, ages, genders, locs, cats)\n",
    "            all_rmse.extend((predictions - ratings).pow(2).cpu().numpy().tolist())\n",
    "\n",
    "        # === HR/NDCG (dengan negative sampling) ===\n",
    "        for row in test_data.itertuples():\n",
    "            user_idx = row.user_idx\n",
    "            pos_item_idx = row.item_idx\n",
    "            age_idx = row.age_idx\n",
    "            gender_idx = row.gender_idx\n",
    "            loc_idx = row.location_idx\n",
    "            cat_idx = row.category_idx\n",
    "            neg_items = row.neg_items\n",
    "\n",
    "            test_items = [pos_item_idx] + neg_items\n",
    "            item_cats = [item_to_category.get(i, 0) for i in test_items]\n",
    "            num_items = len(test_items)\n",
    "\n",
    "            tensors_pred = [\n",
    "                torch.tensor([val] * num_items, device=device)\n",
    "                for val in [user_idx, age_idx, gender_idx, loc_idx]\n",
    "            ]\n",
    "            tensors_pred.insert(1, torch.tensor(test_items, device=device))\n",
    "            tensors_pred.append(torch.tensor(item_cats, device=device))\n",
    "\n",
    "            predictions = model(*tensors_pred)\n",
    "            all_hr_at_10.append(hit_ratio_at_k(predictions, 0, 10))\n",
    "            all_ndcg_at_10.append(ndcg_at_k(predictions, 0, 10))\n",
    "\n",
    "    print(f\"RMSE: {np.sqrt(np.mean(all_rmse)):.4f}\")\n",
    "    print(f\"Hit Ratio @10: {np.mean(all_hr_at_10):.4f}\")\n",
    "    print(f\"NDCG @10: {np.mean(all_ndcg_at_10):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01496c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Selesai | Rata-rata Loss: 0.1903\n",
      "Epoch 2/10 Selesai | Rata-rata Loss: 0.1373\n",
      "Epoch 3/10 Selesai | Rata-rata Loss: 0.1234\n",
      "Epoch 4/10 Selesai | Rata-rata Loss: 0.1189\n",
      "Epoch 5/10 Selesai | Rata-rata Loss: 0.1150\n",
      "Epoch 6/10 Selesai | Rata-rata Loss: 0.1105\n",
      "Epoch 7/10 Selesai | Rata-rata Loss: 0.1050\n",
      "Epoch 8/10 Selesai | Rata-rata Loss: 0.0991\n",
      "Epoch 9/10 Selesai | Rata-rata Loss: 0.0932\n",
      "Epoch 10/10 Selesai | Rata-rata Loss: 0.0874\n",
      "\n",
      "Training selesai dalam 3527.29 detik.\n"
     ]
    }
   ],
   "source": [
    "# Dataset dan dataloader\n",
    "final_train_dataset = FinalHybridDataset(training_df_final)\n",
    "train_loader = DataLoader(final_train_dataset, batch_size=4096, shuffle=True, num_workers=0)\n",
    "\n",
    "# Inisialisasi model dan optimizer\n",
    "model = FinalTwoTowerModel(n_users, n_items, n_ages, n_genders, n_locations, n_categories).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Loop training\n",
    "start_time = time.time()\n",
    "for epoch in range(10): # 10 epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_data in train_loader:\n",
    "        tensors = [t.to(device) for t in batch_data]\n",
    "        users, items, ages, genders, locations, categories, labels = tensors\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(users, items, ages, genders, locations, categories)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/10 Selesai | Rata-rata Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "print(f\"\\nTraining selesai dalam {time.time() - start_time:.2f} detik.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "386340af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluasi Warm Start ---\n",
      "RMSE: 0.5988\n",
      "Hit Ratio @10: 0.7461\n",
      "NDCG @10: 0.4777\n",
      "\n",
      "--- Evaluasi User Cold Start ---\n",
      "RMSE: 0.7481\n",
      "Hit Ratio @10: 0.4050\n",
      "NDCG @10: 0.2252\n",
      "\n",
      "--- Evaluasi Item Cold Start ---\n",
      "RMSE: 0.9869\n",
      "Hit Ratio @10: 0.0096\n",
      "NDCG @10: 0.0034\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi Akhir\n",
    "evaluate_model(model, test_warm_with_neg, \"Evaluasi Warm Start\")\n",
    "evaluate_model(model, user_cold_start_test_with_neg, \"Evaluasi User Cold Start\")\n",
    "evaluate_model(model, item_cold_start_test_with_neg, \"Evaluasi Item Cold Start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8352d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model\n",
    "torch.save(model.state_dict(), \"NCF_TwoTower.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ece40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
